<html>
<head><title>Gromacs</title></head>
<body>
<h1>Gromacs</h1><p><br />
</p>
<div id="toc" class="toc"><div id="toctitle"><h2>Contents</h2></div>
<ul>
<li class="toclevel-1 tocsection-1"><a href="#R.C3.A9f.C3.A9rent_local"><span class="tocnumber">1</span> <span class="toctext">Référent local</span></a></li>
<li class="toclevel-1 tocsection-2"><a href="#Latest_Version"><span class="tocnumber">2</span> <span class="toctext">Latest Version</span></a></li>
<li class="toclevel-1 tocsection-3"><a href="#Web_site"><span class="tocnumber">3</span> <span class="toctext">Web site</span></a></li>
<li class="toclevel-1 tocsection-4"><a href="#gromacs_5_.2B_plumed"><span class="tocnumber">4</span> <span class="toctext">gromacs 5 + plumed</span></a></li>
<li class="toclevel-1 tocsection-5"><a href="#Benchmark"><span class="tocnumber">5</span> <span class="toctext">Benchmark</span></a>
<ul>
<li class="toclevel-2 tocsection-6"><a href="#CG_lipid_lynn_26k"><span class="tocnumber">5.1</span> <span class="toctext">CG_lipid_lynn_26k</span></a></li>
<li class="toclevel-2 tocsection-7"><a href="#Lipid_Bilayer_all_atoms_88k"><span class="tocnumber">5.2</span> <span class="toctext">Lipid_Bilayer_all_atoms_88k</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-8"><a href="#logiciel_Gromacs_sur_les_clusters"><span class="tocnumber">6</span> <span class="toctext">logiciel Gromacs sur les clusters</span></a></li>
<li class="toclevel-1 tocsection-9"><a href="#Test_gromacs"><span class="tocnumber">7</span> <span class="toctext">Test gromacs</span></a></li>
<li class="toclevel-1 tocsection-10"><a href="#Matrice_de_compatibilit.C3.A9_CUDA_-_compilateur"><span class="tocnumber">8</span> <span class="toctext">Matrice de compatibilité CUDA - compilateur</span></a></li>
<li class="toclevel-1 tocsection-11"><a href="#Compilation_version_2019.5_avec_intel18u3"><span class="tocnumber">9</span> <span class="toctext">Compilation version 2019.5 avec intel18u3</span></a></li>
<li class="toclevel-1 tocsection-12"><a href="#Compilation_version_2016.3_sur_KECH"><span class="tocnumber">10</span> <span class="toctext">Compilation version 2016.3 sur KECH</span></a>
<ul>
<li class="toclevel-2 tocsection-13"><a href="#version_GCC_avec_notre_FFT"><span class="tocnumber">10.1</span> <span class="toctext">version GCC avec notre FFT</span></a></li>
<li class="toclevel-2 tocsection-14"><a href="#version_intel_avec_notre_FFT"><span class="tocnumber">10.2</span> <span class="toctext">version intel avec notre FFT</span></a></li>
<li class="toclevel-2 tocsection-15"><a href="#version_intel_avec_FFT_des_MKL_intel"><span class="tocnumber">10.3</span> <span class="toctext">version intel avec FFT des MKL intel</span></a></li>
<li class="toclevel-2 tocsection-16"><a href="#version_GCC_pour_GPU_avec_notre_FFT"><span class="tocnumber">10.4</span> <span class="toctext">version GCC pour GPU avec notre FFT</span></a></li>
<li class="toclevel-2 tocsection-17"><a href="#version_intel_pour_GPU_avec_FFT_des_MKL_intel"><span class="tocnumber">10.5</span> <span class="toctext">version intel pour GPU avec FFT des MKL intel</span></a></li>
<li class="toclevel-2 tocsection-18"><a href="#Execution_des_scripts"><span class="tocnumber">10.6</span> <span class="toctext">Execution des scripts</span></a></li>
</ul>
</li>
<li class="toclevel-1 tocsection-19"><a href="#Compilation_sur_EXPLOR"><span class="tocnumber">11</span> <span class="toctext">Compilation sur EXPLOR</span></a>
<ul>
<li class="toclevel-2 tocsection-20"><a href="#installation_cmake"><span class="tocnumber">11.1</span> <span class="toctext">installation cmake</span></a></li>
<li class="toclevel-2 tocsection-21"><a href="#simple_gcc_opnempi"><span class="tocnumber">11.2</span> <span class="toctext">simple gcc opnempi</span></a></li>
<li class="toclevel-2 tocsection-22"><a href="#simple_intel"><span class="tocnumber">11.3</span> <span class="toctext">simple intel</span></a></li>
<li class="toclevel-2 tocsection-23"><a href="#intel_.2B_intelMPI_.2B_MKL"><span class="tocnumber">11.4</span> <span class="toctext">intel + intelMPI + MKL</span></a></li>
<li class="toclevel-2 tocsection-24"><a href="#compilation_gromacs_5.1.4_explor"><span class="tocnumber">11.5</span> <span class="toctext">compilation gromacs 5.1.4 explor</span></a></li>
<li class="toclevel-2 tocsection-25"><a href="#STATIC_gnu_5.2.0_.2B_openmpi_.2B_FFT"><span class="tocnumber">11.6</span> <span class="toctext">STATIC gnu 5.2.0 + openmpi + FFT</span></a></li>
</ul>
</li>
</ul>
</div>

<h1><span class="mw-headline" id="R.C3.A9f.C3.A9rent_local">Référent local</span></h1>
<p>Mounir Tarek
</p>
<ul><li> Contexte d'utilisation:</li></ul>
<p>Utilisation des ressources locales en soutien au grand centre. Besoin de générer des dynamiques de plusieurs jours facilement et rapidement.
</p>
<h1><span class="mw-headline" id="Latest_Version">Latest Version</span></h1>
<ul><li> 2021.2 compiled with gnu7.5.0, cuda10.2, ownFFT, internal BLAS</li></ul>
<pre>
#!/bin/bash
#SBATCH -p kech3
#SBATCH -N 1
#SBATCH -n 20 
#SBATCH -J test
#SBATCH -o slurm%j.log
#SBATCH -e slurm%j.log
#SBATCH --gres=gpu:2

module load gromacs/2021.2-gnu7_cuda10_fftw_openMP

WORKDIR="out2"
mkdir -p $WORKDIR
cp -v "${SLURM_SUBMIT_DIR}"* "$WORKDIR"
cd $WORKDIR

gmx grompp -f step7_production.mdp -o step7_production.tpr -c step6.6_equilibration.gro -p system.top -n index.ndx -maxwarn 10 &gt;&amp; GROMPPstep7.LOG
gmx mdrun   -deffnm  step7_production
</pre>
<h1><span class="mw-headline" id="Web_site">Web site</span></h1>
<p><a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="http://www.gromacs.org/">http://www.gromacs.org/</a>
</p>
<h1><span class="mw-headline" id="gromacs_5_.2B_plumed">gromacs 5 + plumed</span></h1>
<p><a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="http://cbp.cfn.kit.edu/joomla/index.php/downloads/18-gromacs-with-qm-mm-using-dftb3">http://cbp.cfn.kit.edu/joomla/index.php/downloads/18-gromacs-with-qm-mm-using-dftb3</a>
</p>
<ul><li> Get Gromacs version 5.0 from the Gromacs website"</li></ul>
<pre>wget <a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="ftp://ftp.gromacs.org/pub/gromacs/gromacs-5.0.tar.gz">ftp://ftp.gromacs.org/pub/gromacs/gromacs-5.0.tar.gz</a>
</pre>
<ul><li> Get Plumed, so you will need to get Plumed version 2.1 or 2.1.x. Install Plumed, but do not patch the Gromacs source yet.</li></ul>
<pre>wget <a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="https://github.com/plumed/plumed2/archive/v2.1.5.tar.gz">https://github.com/plumed/plumed2/archive/v2.1.5.tar.gz</a>
</pre>
<pre> tar -zxf v2.1.5.tar.gz
 cd plumed2-2.1.5/
 module load compiler/gnu-5.2.0/std 
 ./configure --prefix=/auto/soft/plumed/2.1.5-gnu-5.2.0
 make
 make install
 make doc
</pre>
<pre>
export PATH="/auto/soft/plumed/2.1.5-gnu-5.2.0/bin/:$PATH"
export LIBRARY_PATH="/auto/soft/plumed/2.1.5-gnu-5.2.0/lib/plumed/src:$LIBRARY_PATH"
export LD_LIBRARY_PATH="/auto/soft/plumed/2.1.5-gnu-5.2.0/lib/:$LD_LIBRARY_PATH"
export DYLD_LIBRARY_PATH="/auto/soft/plumed/2.1.5-gnu-5.2.0/lib/:$DYLD_LIBRARY_PATH"
export PLUMED_KERNEL="/auto/soft/plumed/2.1.5-gnu-5.2.0/lib/libplumedKernel.so"
</pre>
<ul><li> Get the actual DFTB implementation in the form of a patch to Gromacs, new bugfix release from 30 Oct 2015</li></ul>
<pre>tar -zxf gromacs-5.0.tar.gz
wget <a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="http://cbp.cfn.kit.edu/joomla/downloads/gromacs-5.0-dftb-v6a-plumed.patch.tgz">http://cbp.cfn.kit.edu/joomla/downloads/gromacs-5.0-dftb-v6a-plumed.patch.tgz</a>
</pre>
<p><br />
</p>
<ul><li> Patch the Gromacs source with the file just downloaded:</li></ul>
<pre>tar xvzf gromacs-5.0-dftb-v6-plumed.patch.tgz
</pre>
<pre>patch -p0 &lt; gromacs-5.0-dftb-v6a-plumed.patch
</pre>
<p>Manually correct the references to the libplumed.so or libplumed.a file in the Gromacs main directory, files Plumed.cmake and Plumed.inc (two occurrences in each file), to match your installation.
</p>
<pre>
 sed -i 's/\/home\/tomas\/GMX-DFTB\/plumed-2.1.1-release\/lib\/plumed\/src\/lib\/libplumed.so/\/auto\/soft\/plumed\/2.1.5-gnu-5.2.0\/lib\/plumed\/src\/lib\/libplumed.so/' Plumed.cmake 
 sed -i 's/\/home\/tomas\/GMX-DFTB\/plumed-2.1.1-release\/lib\/plumed\/src\/lib\/libplumed.so/\/auto\/soft\/plumed\/2.1.5-gnu-5.2.0\/lib\/plumed\/src\/lib\/libplumed.so/' Plumed.inc
</pre>
<p>Compile Gromacs. Choose 'dftb' for GMX_QMMM_PROGRAM, and disable CUDA as well as all of the parallelization options (MPI, THREAD_MPI and OPENMP). It may be a good idea to compile in double precision (GMX_DOUBLE=ON). There may be issues when you link against MKL for linear algebra libraries; it you have solved these, please let us know.
</p>
<h1><span class="mw-headline" id="Benchmark">Benchmark</span></h1>
<h2><span class="mw-headline" id="CG_lipid_lynn_26k">CG_lipid_lynn_26k</span></h2>
<ul><li> git clone <a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="ssh://git@gitserver.lctn.uhp-nancy.fr/bench-gromacs">ssh://git@gitserver.lctn.uhp-nancy.fr/bench-gromacs</a></li></ul>
<ul><li> <b>sge_gromacs.sh</b>&#160;: script sge qui permet de lancer le job sous SGE sur les clusters bolo et lisboa</li></ul>
<ul><li> <b>CG_lipid_lynn_26k/submit_local_avec_statistique.sh</b></li></ul>
<h2><span class="mw-headline" id="Lipid_Bilayer_all_atoms_88k">Lipid_Bilayer_all_atoms_88k</span></h2>
<pre>256 Lipids (POPC)  + water + ions
total number of atoms ( site)&#160;: 88072
lipid bilayer 
charmm FF, all atom simulations
</pre>
<h1><span class="mw-headline" id="logiciel_Gromacs_sur_les_clusters">logiciel Gromacs sur les clusters</span></h1>
<p><a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="http://wiki.lctn.uhp-nancy.fr/index.php/Gromacs">http://wiki.lctn.uhp-nancy.fr/index.php/Gromacs</a>
</p>
<h1><span class="mw-headline" id="Test_gromacs">Test gromacs</span></h1>
<pre>
#!/bin/bash

#SBATCH -p v100
#SBATCH -N 1
#SBATCH -n 16
#SBATCH --gres=gpu:1
#SBATCH -e slurm.out
#SBATCH -o slurm.out
#SBATCH -J test1

module load gromacs/5.1.2-local-gnu-4.4.6/std

OUT="out_gnu"

RUN="disk_pept"

RUNOPT=''
RUNOPT='-ntomp 2'

OUTBENCH="${SLURM_SUBMIT_DIR}/${OUT}"
mkdir -p "${OUTBENCH}"

cp -a "${SLURM_SUBMIT_DIR}/$RUN/"* "${OUTBENCH}/"

cd "${OUTBENCH}"

module load gromacs/intel18_cuda10_avx512_openMP_MPI

mpirun  -np ${SLURM_NTASKS} gmx_mpi grompp -f step7_tarek.mdp -o step7_tarek.tpr -c step6.6_equilibration.gro -r step6.6_equilibration.gro -p topol.top -n index.ndx -maxwarn 10 &gt;&amp; GROMPPstep7.LOG
mpirun  -np ${SLURM_NTASKS} gmx_mpi  mdrun $RUNOPT -deffnm step7_tarek &gt;&amp; MDRUN.LOG 

</pre>
<h1><span class="mw-headline" id="Matrice_de_compatibilit.C3.A9_CUDA_-_compilateur">Matrice de compatibilité CUDA - compilateur</span></h1>
<p><a target="_blank" rel="nofollow noreferrer noopener" class="external free" href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements">https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements</a>
</p>
<h1><span class="mw-headline" id="Compilation_version_2019.5_avec_intel18u3">Compilation version 2019.5 avec intel18u3</span></h1>
<p>Cette version ne support que les compilateurs intel &gt; 19
</p>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
export MODULEPATH=/auto/soft/EasyBuild/modules/all/:$MODULEPATH
export PREFIX="intel19u5_cuda9_avx512_openMP_MPI0"
export GromacsPath="/auto/store/fpascale/gromacs-2019.5"

module load compiler/GCC/7.4.0-2.31.1 devel/CMake/3.12.1 system/CUDA/10.0.130 

source /auto/soft/compiler/intel/psxe-18.3//bin/compilervars.sh intel64   # Source the Intel compiler, Intel MKL and Intel MPI Library
source /auto/soft/compiler/intel/psxe-18.3/parallel_studio_xe_2018/bin/psxevars.sh intel64
source /auto/soft/compiler/intel/psxe-18.3/compilers_and_libraries/linux/bin/compilervars.sh intel64
source /auto/soft/compiler/intel/psxe-18.3/impi/intel64/bin/mpivars.sh
source /auto/soft/compiler/intel/psxe-18.3/mkl/bin/mklvars.sh  intel64

export FLAGS="-xCORE-AVX512 ";
export CFLAGS=$FLAGS 
export CXXFLAGS=$FLAGS 
export CC=mpiicc 
export CXX=mpiicpc 

cd "${GromacsPath}"

rm -rf  build-${PREFIX}
mkdir   build-${PREFIX}
rm -rf  exec-${PREFIX}
mkdir   exec-${PREFIX}

cd      build-${PREFIX}

cmake .. \
-DBUILD_SHARED_LIBS=ON \
-DGMX_FFT_LIBRARY=mkl \
-DCMAKE_INSTALL_PREFIX="${GromacsPath}/exec-${PREFIX}" \
-DGMX_MPI=ON \
-DGMX_OPENMP=ON \
-DGMX_CYCLE_SUBCOUNTERS=ON \
-DGMX_GPU=ON \
-DGMX_BUILD_HELP=OFF \
-DGMX_HWLOC=OFF \
-DGMX_SIMD=AVX_512 \
-DGMX_OPENMP_MAX_THREADS=256 \
-DGMX_PREFER_STATIC_LIBS=ON \
-DGMX_BUILD_SHARED_EXE=ON

make -j32 -l32
make  install
</pre>
<h1><span class="mw-headline" id="Compilation_version_2016.3_sur_KECH">Compilation version 2016.3 sur KECH</span></h1>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
wget http://ftp.gromacs.org/pub/gromacs/gromacs-2016.3.tar.gz

tar -zxf gromacs-2016.3.tar.gz

cd gromacs-2016.3
</pre>
<h2><span class="mw-headline" id="version_GCC_avec_notre_FFT">version GCC avec notre FFT</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 

cat &gt; compile_gcc.sh &lt;&lt; EOF
export PATH=\$PATH:/usr/local/cuda/bin/:/home/fpascale/cmake/bin/
export CXX=g++
export CC=gcc

PREFIX="gcc_seq_kech"
rm -rf   \$PREFIX
mkdir  \$PREFIX
cd \$PREFIX
rm -rf  exec-\$PREFIX
mkdir exec-\$PREFIX
cmake ..  \
 -DREGRESSIONTEST_DOWNLOAD=OFF  \
 -DGMX_GPU=OFF  \
 -DGMX_OPENMM=OFF  \
 -DGMX_MPI=OFF  \
 -DGMX_FFT_LIBRARY=fftw3 \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DCMAKE_INSTALL_PREFIX=/home/\$USER/gromacs-2016.3/exec-\$PREFIX 

make -j10 -l10
make  install
EOF
</pre>
<h2><span class="mw-headline" id="version_intel_avec_notre_FFT">version intel avec notre FFT</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
cat &gt; compile_intel.sh &lt;&lt; EOF
module load intel/16.0.1.150
export CXX=icc
export CC=icc

PREFIX="intel16_seq_kech"

rm -rf   \$PREFIX
mkdir  \$PREFIX
cd \$PREFIX
rm -rf  exec-\$PREFIX
mkdir exec-\$PREFIX

cmake ..  \
 -DREGRESSIONTEST_DOWNLOAD=OFF  \
 -DGMX_GPU=OFF  \
 -DGMX_OPENMM=OFF  \
 -DGMX_MPI=OFF  \
 -DGMX_FFT_LIBRARY=fftw3 \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DCMAKE_INSTALL_PREFIX=/home/\$USER/gromacs-2016.3/exec-\$PREFIX 

make -j10 -l10
make  install
EOF
</pre>
<h2><span class="mw-headline" id="version_intel_avec_FFT_des_MKL_intel">version intel avec FFT des MKL intel</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
cat &gt; compile_intel_mkl.sh &lt;&lt; EOF
module load intel/16.0.1.150
export CXX=icc
export CC=icc

PREFIX="intel16_seq_kech"

rm -rf   \$PREFIX
mkdir  \$PREFIX
cd \$PREFIX
rm -rf  exec-\$PREFIX
mkdir exec-\$PREFIX

cmake ..  \
 -DREGRESSIONTEST_DOWNLOAD=OFF  \
 -DGMX_GPU=OFF  \
 -DGMX_OPENMM=OFF  \
 -DGMX_MPI=OFF  \
 -DGMX_FFT_LIBRARY=mkl \
 -DCMAKE_INSTALL_PREFIX=/home/\$USER/gromacs-2016.3/exec-\$PREFIX 

make -j10 -l10
make  install
EOF
</pre>
<h2><span class="mw-headline" id="version_GCC_pour_GPU_avec_notre_FFT">version GCC pour GPU avec notre FFT</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
cat &gt; compile_gcc_gpu.sh &lt;&lt; EOF
export PATH=\$PATH:/usr/local/cuda/bin/:/home/fpascale/cmake/bin/

export CXX=gcc
export CC=gcc
PREFIX="gcc_gpu_seq_kech"
rm -rf   \$PREFIX
mkdir  \$PREFIX
cd \$PREFIX
rm -rf  exec-
mkdir exec-
cmake ..  \
 -DREGRESSIONTEST_DOWNLOAD=OFF  \
 -DGMX_GPU=ON  \
 -DGMX_OPENMM=OFF  \
 -DGMX_MPI=OFF  \
 -DGMX_FFT_LIBRARY=fftw \
 -DCUDA_SDK_ROOT_DIR=/usr/local/cuda \
 -DCMAKE_INSTALL_PREFIX=/home/\$USER/gromacs-2016.3/exec-\$PREFIX 
make -j10 -l10
make  install
EOF
</pre>
<h2><span class="mw-headline" id="version_intel_pour_GPU_avec_FFT_des_MKL_intel">version intel pour GPU avec FFT des MKL intel</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-cat"> compile_intel_mkl_gpu.sh &lt;&lt;EOF
module load intel/16.0.1.150

export CXX=icc
export CC=icc
PREFIX="intel16_gpu_seq_mkl_kech"
rm -rf   \$PREFIX
mkdir  \$PREFIX
cd \$PREFIX
rm -rf  exec-
mkdir exec-
cmake ..  \
 -DREGRESSIONTEST_DOWNLOAD=OFF  \
 -DGMX_GPU=ON  \
 -DGMX_OPENMM=OFF  \
 -DGMX_MPI=OFF  \
 -DGMX_FFT_LIBRARY=mkl \
 -DCUDA_SDK_ROOT_DIR=/usr/local/cuda \
 -DCMAKE_INSTALL_PREFIX=/home/\$USER/exec-\$PREFIX 
make -j10 -l10
make  install
EOF
</pre>
<h2><span class="mw-headline" id="Execution_des_scripts">Execution des scripts</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-sh ./compile_gcc.sh &lt;/pre"></pre>&lt;/pre&gt;
<h1><span class="mw-headline" id="Compilation_sur_EXPLOR">Compilation sur EXPLOR</span></h1>
<h2><span class="mw-headline" id="installation_cmake">installation cmake</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 

srun -N1 --exclusive --pty bash
wget https://cmake.org/files/v3.8/cmake-3.8.1.tar.gz
tar -zxf cmake-3.8.1.tar.gz
cd cmake-3.8.1

export CXX=g++

./configure --prefix=/gce17/vbh43/fabien/cmake-3.8.1_gcc4.8.5

gmake -j32

gmake install

# TEST
/gce17/vbh43/fabien/cmake-3.8.1_gcc4.8.5/bin/ctest

export PATH=/gce17/vbh43/fabien/cmake-3.8.1_gcc4.8.5/bin:$PATH
</pre>
<h2><span class="mw-headline" id="simple_gcc_opnempi">simple gcc opnempi</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
# A lancer dans le repertoire avec les sources Gromacs

# cmake perso
export PATH=/home/gce17/vbh43/fabien/bin:$PATH

module purge

module load gcc/6.3.0
module load openmpi/2.1.0/gcc

MA="-gcc6.3-openmpi2.1"

export CC=mpicc
export CXX=mpicc
export CFLAGS="-O3 -fPIC -DKML_L64"

H=$(hostname | sed 's/^\(...\).*$/\1/')

R="${H}${MA}"
S="exec-$R"
PREF=$(pwd)/$S

rm -rf  $S
mkdir $S

rm -rf $R
mkdir $R

# Dans le repertoire build temporaire
cd $R

cmake .. \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DREGRESSIONTEST_DOWNLOAD=OFF \
 -DGMX_OPENMM=ON \
 -DGMX_GPU=OFF \
 -DGMX_MPI=ON \
 -DCMAKE_INSTALL_PREFIX=$PREF \
 -DGMX_X11=OFF \

make -j 32
make  install

cd ..

# read entry to pause installation
read 

rm -rf $R

</pre>
<h2><span class="mw-headline" id="simple_intel">simple intel</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
# A lancer dans le repertoire avec les sources Gromacs

# cmake perso
export PATH=/home/gce17/vbh43/fabien/bin:$PATH

module purge

source /opt/intel/bin/compilervars.sh intel64
source /opt/intel/compilers_and_libraries_2017/linux/mpi/intel64/bin/mpivars.sh
source /opt/intel/compilers_and_libraries_2017/linux/mkl/bin/mklvars.sh intel64

export CC=mpiicc
export CXX=mpiicc
export CFLAGS="-O3 -fPIC -DKML_L64"

H=$(hostname | sed 's/^\(...\).*$/\1/')
MA="-intel17-intelmpi-mkl"
R="${H}${MA}"
S="exec-$R"
PREF=$(pwd)/$S

rm -rf  $S
mkdir $S

rm -rf $R
mkdir $R

# Dans le repertoire build temporaire
cd $R

cmake .. \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DREGRESSIONTEST_DOWNLOAD=OFF \
 -DGMX_OPENMM=ON \
 -DGMX_GPU=OFF \
 -DGMX_MPI=ON \
 -DCMAKE_INSTALL_PREFIX=$PREF \
 -DGMX_X11=OFF \

make -j 32
make  install

cd ..

# read entry to pause installation
read 

rm -rf $R

</pre>
<h2><span class="mw-headline" id="intel_.2B_intelMPI_.2B_MKL">intel + intelMPI + MKL</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 
#!/bin/bash

#set -x

#srun -N1 --exclusive --time=4:00:00 --pty bash

export PATH=/home/gce17/vbh43/fabien/bin:$PATH

G=/home/gce17/vbh43/fabien/regressiontests

module purge

if [ $# -lt 1 ]; then
   echo "usage: $0 liste modules "
   exit 1
fi

MA=""
LISTM=${@:1}

#for m in intelmpi/2017.1.132 mkl/2017.1.132&#160;; do
for m in $LISTM&#160;; do
   echo module load $m;
   module load $m;
   M=""
   M=$(echo $m | sed "s/\//-/g")
   MA="${MA}-${M}"
done

source /opt/intel/bin/compilervars.sh intel64
source /opt/intel/compilers_and_libraries_2017/linux/mpi/intel64/bin/mpivars.sh
source /opt/intel/compilers_and_libraries_2017/linux/mkl/bin/mklvars.sh intel64

#if hash mpicc 2&gt; /dev/null&#160;; then
  echo "icc exists"
  export CC=mpiicc
  export CXX=mpiicc
#  export F77=mpiifort
  export CFLAGS="-O3 -fPIC -DKML_L64"
#  export CFLAGS="-O3 -ip -static -std=c99 -fPIC -DMKL_LP64 -DM_PI=3.1415926535897932384"
#  export CPPFLAGS="-I$MKLROOT/include -I$MKLROOT/include/fftw"
#  export LDFLAGS="-L$MKLROOT/lib/intel64 -L$MKLROOT/../compiler/lib/intel64"
#  export LD_LIBRARY_PATH="$MKLROOT/lib/intel64:$MKLROOT/../compiler/lib/intel64:$LD_LIBRARY_PATH"
#fi

echo module
module list


H=$(hostname | sed 's/^\(...\).*$/\1/')
R="${H}${MA}"
S="exec-$R"
PREF=$(pwd)/$S

env

rm -rf  $S
mkdir $S

rm -rf $R
mkdir $R
cd $R



#cmake .. \
# -DREGRESSIONTEST_DOWNLOAD=ON \
# -DGMX_BUILD_OWN_FFTW=ON \
# -DCMAKE_INSTALL_PREFIX=$(pwd)/../$S 

cmake .. \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DREGRESSIONTEST_DOWNLOAD=OFF \
 -DREGRESSIONTEST_PATH=$G \
 -DGMX_OPENMM=ON \
 -DGMX_GPU=OFF \
 -DGMX_MPI=ON \
 -DCMAKE_INSTALL_PREFIX=$PREF \
 -DGMX_X11=OFF \
# -DGMX_THREAD_MPI=ON \
# -DGMX_BUILD_OWN_FFTW_URL=../../fftw-3.3.4.tar.gz \
# -DCUDA_SDK_ROOT_DIR=/usr/local/cuda \

make -j 32

make  install

cd ..
rm -rf $R
</pre>
<p><br />
</p>
<h2><span class="mw-headline" id="compilation_gromacs_5.1.4_explor">compilation gromacs 5.1.4 explor</span></h2>
<pre> srun -N1 -n 8 --gres=gpu:1 --time 60:00 -p p100 --pty bash
</pre>
<p><br />
Change in cmake/gmxManageNvccConfig.cmake file line 203 to 243
</p>
<pre>
203     # First add flags that trigger SASS (binary) code generation for physical arch
204     if(CUDA_VERSION VERSION_LESS "9.00") # &lt; 9.0
205       list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_20,code=sm_20")
206     endif()
207 
208     if(NOT CUDA_VERSION VERSION_LESS "4.2") # &gt;= 4.2
209         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_30,code=sm_30")
210     endif()
211     if(NOT CUDA_VERSION VERSION_LESS "5.0") # &gt;= 5.0
212         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_35,code=sm_35")
213     endif()
214     if(NOT CUDA_VERSION VERSION_LESS "6.5") # &gt;= 6.5
215         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_37,code=sm_37")
216         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_50,code=sm_50")
217     endif()
218     if(NOT CUDA_VERSION VERSION_LESS "7.0") # &gt;= 7.0
219         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_52,code=sm_52")
220     endif()
221     if(NOT CUDA_VERSION VERSION_LESS "8.0") # &gt;= 8.0
222         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_60,code=sm_60")
223         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_61,code=sm_61")
224     endif()
225 
226     # Next add flags that trigger PTX code generation for the newest supported virtual arch
227     # that's useful to JIT to future architectures
228     if(CUDA_VERSION VERSION_LESS "4.2")
229         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_20,code=compute_20")
230     elseif(CUDA_VERSION VERSION_LESS "5.0")
231         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_30,code=compute_30")
232     elseif(CUDA_VERSION VERSION_LESS "6.5")
233         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_35,code=compute_35")
234     elseif(CUDA_VERSION VERSION_LESS "7.0")
235         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_50,code=compute_50")
236     elseif(CUDA_VERSION VERSION_LESS "8.0")
237         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_52,code=compute_52")
238     elseif(CUDA_VERSION VERSION_LESS "9.0")
239         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_60,code=compute_60")
240         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_61,code=compute_61")
241     else() # version &gt;= 9.0
242         list (APPEND GMX_CUDA_NVCC_GENCODE_FLAGS "-gencode;arch=compute_70,code=compute_70")
243     endif()

</pre>
<pre>
#!/bin/bash

#SBATCH -N 1 
#SBATCH -n 8 
#SBATCH --gres=gpu:1 
#SBATCH --time 60:00 
#SBATCH -p p100 
#SBATCH -e slurm.log
#SBATCH -o slurm.log

module load intel/2017.1.132 cuda/9.1 cmake/3.10.2
module load cuda/9.1

export CXX=icpc
export CC=icc

export NVML_LIBRARY=/opt/soft/all/cuda-9.1/lib64/stubs/libnvidia-ml.so 
export NVML_INCLUDE_DIR=/opt/soft/all/cuda-9.1/include 

export PREFIX="intel17-fftw"

rm -rf   /home/pmg89/shared/gromacs-5.1.4/${PREFIX}
mkdir  /home/pmg89/shared/gromacs-5.1.4/${PREFIX}
cd /home/pmg89/shared/gromacs-5.1.4/${PREFIX}
rm -rf  /home/pmg89/shared/gromacs-5.1.4/exec-${PREFIX}
mkdir /home/pmg89/shared/gromacs-5.1.4/exec-${PREFIX}


cmake .. \
 -DREGRESSIONTEST_DOWNLOAD=OFF \
 -DGMX_GPU=ON \
 -DNVML_LIBRARY=/opt/soft/all/cuda-9.1/lib64/stubs/libnvidia-ml.so \
 -DNVML_INCLUDE_DIR=/opt/soft/all/cuda-9.1/include \
 -DGMX_OPENMM=ON \
 -DGMX_MPI=OFF \
 -DGMX_FFT_LIBRARY=fftw3  \
 -DGMX_BUILD_OWN_FFTW=ON \
 -DGMX_BUILD_OWN_FFTW_URL:PATH=/home/pmg89/shared/gromacs-5.1.4/fftw-3.3.4.tar.gz \
 -DCMAKE_INSTALL_PREFIX=/home/pmg89/shared/gromacs-5.1.4/exec-${PREFIX}

make -j8 -l8
make  install
</pre>
<h2><span class="mw-headline" id="STATIC_gnu_5.2.0_.2B_openmpi_.2B_FFT">STATIC gnu 5.2.0 + openmpi + FFT</span></h2>
<pre style="white-space: pre-wrap; white-space: -moz-pre-wrap; white-space: -pre-wrap; white-space: -o-pre-wrap; word-wrap: break-word;"> 

</pre>




</body></html>